{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ede629bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T14:59:14.849680Z",
     "start_time": "2022-10-29T14:59:06.187169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted  Error\n",
      "0         4          4      0\n",
      "1         1          9      1\n",
      "2         2          2      0\n",
      "3         4          4      0\n",
      "4         9          9      0\n",
      "..      ...        ...    ...\n",
      "355       4          4      0\n",
      "356       6          6      0\n",
      "357       4          4      0\n",
      "358       3          3      0\n",
      "359       0          0      0\n",
      "\n",
      "[360 rows x 3 columns]\n",
      "   Accuracy of SVM\n",
      "0         0.994444\n",
      "1         0.975000\n",
      "2         0.994444\n",
      "3         1.000000\n",
      "4         0.994444\n",
      "Mean:  0.9916666666666668\n",
      "Std:  0.008606629658238716\n",
      "\n",
      "\n",
      "   Accuracy of DTree\n",
      "0           0.822222\n",
      "1           0.822222\n",
      "2           0.838889\n",
      "3           0.788889\n",
      "4           0.819444\n",
      "Mean:  0.8183333333333334\n",
      "Std:  0.016254154264808668\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#resize(image, (100, 100)).shape(100, 100)\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. set the ranges of hyper parameters \n",
    "gamma_list = [0.01, 0.005, 0.001]\n",
    "c_list = [0.1, 0.2, 0.5] \n",
    "\n",
    "h_param_comb = [{'gamma':g, 'C':c} for g in gamma_list for c in c_list]\n",
    "\n",
    "assert len(h_param_comb) == len(gamma_list)*len(c_list)\n",
    "\n",
    "\n",
    "report = pd.DataFrame(h_param_comb)\n",
    "#print(report.head())\n",
    "\n",
    "\n",
    "train_frac = 0.7\n",
    "test_frac = 0.2\n",
    "dev_frac = 0.1\n",
    "\n",
    "#PART: load dataset -- data from csv, tsv, jsonl, pickle\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "#digits = datasets.load_digits()\n",
    "data = digits.images\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "dev_test_frac = 1-train_frac\n",
    "\n",
    "\n",
    "best_acc = -1.0\n",
    "best_model = None\n",
    "best_h_params = None\n",
    "\n",
    "#width, height = X_train.size\n",
    "\n",
    "#print(width, height)\n",
    "\n",
    "\n",
    "svm_accuracy = []\n",
    "\n",
    "# 2. For every combination-of-hyper-parameter values\n",
    "for i in range(0,5):\n",
    "    X_train, X_dev_test, y_train, y_dev_test = train_test_split(\n",
    "    data, digits.target, test_size=dev_test_frac, shuffle=True\n",
    "    )\n",
    "    X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "    X_dev_test, y_dev_test, test_size=(dev_frac)/dev_test_frac, shuffle=True\n",
    "    )\n",
    "    for cur_h_params in h_param_comb:\n",
    "\n",
    "        #PART: Define the model\n",
    "        # Create a classifier: a support vector classifier\n",
    "        clf = svm.SVC()\n",
    "\n",
    "        #PART: setting up hyperparameter\n",
    "        hyper_params = cur_h_params\n",
    "        clf.set_params(**hyper_params)\n",
    "\n",
    "\n",
    "        #PART: Train model\n",
    "        # 2.a train the model \n",
    "        # Learn the digits on the train subset\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # print(cur_h_params)\n",
    "        #PART: get dev set predictions\n",
    "        predicted_dev = clf.predict(X_test)\n",
    "\n",
    "        # 2.b compute the accuracy on the validation set\n",
    "        cur_acc = metrics.accuracy_score(y_pred=predicted_dev, y_true=y_test)\n",
    "        \n",
    "\n",
    "        # 3. identify the combination-of-hyper-parameter for which validation set accuracy is the highest. \n",
    "        if cur_acc > best_acc:\n",
    "            best_acc = cur_acc\n",
    "            best_model = clf\n",
    "            best_h_params = cur_h_params\n",
    "            #print(\"Found new best acc with :\"+str(cur_h_params))\n",
    "            #print(\"New best val accuracy:\" + str(cur_acc)\n",
    "    svm_accuracy.append(cur_acc)\n",
    "            \n",
    "#predicted = best_model.predict(X_test)\n",
    "#print(\"Best hyperparameters were:\")\n",
    "#print(cur_h_params)\n",
    "#print(accuracy)\n",
    "#accuracy = pd.DataFrame(accuracy,columns=['acc'])\n",
    "#final_report = pd.concat([report,accuracy],axis=1)\n",
    "#final_report\n",
    "#print(svm_accuracy)\n",
    "\n",
    "\n",
    "best_acc = -1.0\n",
    "best_model = None\n",
    "best_h_params = None\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "max_depth = [10, 50, 100]\n",
    "min_samples_split = [2,4,6] \n",
    "\n",
    "h_param_comb = [{'max_depth':g, 'min_samples_split':c} for g in max_depth for c in min_samples_split]\n",
    "\n",
    "assert len(h_param_comb) == len(max_depth)*len(min_samples_split)\n",
    "\n",
    "dt_accuracy = []\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "    X_train, X_dev_test, y_train, y_dev_test = train_test_split(\n",
    "    data, digits.target, test_size=dev_test_frac, shuffle=True\n",
    "    )\n",
    "    X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "    X_dev_test, y_dev_test, test_size=(dev_frac)/dev_test_frac, shuffle=True\n",
    "    )\n",
    "    for cur_h_params in h_param_comb:\n",
    "\n",
    "        #PART: Define the model\n",
    "        # Create a classifier: a support vector classifier\n",
    "        clf = DecisionTreeClassifier()\n",
    "\n",
    "        #PART: setting up hyperparameter\n",
    "        hyper_params = cur_h_params\n",
    "        clf.set_params(**hyper_params)\n",
    "\n",
    "\n",
    "        #PART: Train model\n",
    "        # 2.a train the model \n",
    "        # Learn the digits on the train subset\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # print(cur_h_params)\n",
    "        #PART: get dev set predictions\n",
    "        predicted_dev = clf.predict(X_test)\n",
    "\n",
    "        # 2.b compute the accuracy on the validation set\n",
    "        cur_acc = metrics.accuracy_score(y_pred=predicted_dev, y_true=y_test)\n",
    "        \n",
    "\n",
    "        # 3. identify the combination-of-hyper-parameter for which validation set accuracy is the highest. \n",
    "        if cur_acc > best_acc:\n",
    "            best_acc = cur_acc\n",
    "            best_model = clf\n",
    "            best_h_params = cur_h_params\n",
    "            #print(\"Found new best acc with :\"+str(cur_h_params))\n",
    "            #print(\"New best val accuracy:\" + str(cur_acc)\n",
    "    dt_accuracy.append(cur_acc)\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "#print(best_h_params)\n",
    "        #PART: setting up hyperparameter\n",
    "X_train, X_dev_test, y_train, y_dev_test = train_test_split(\n",
    "data, digits.target, test_size=dev_test_frac, shuffle=True\n",
    ")\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "X_dev_test, y_dev_test, test_size=(dev_frac)/dev_test_frac, shuffle=True\n",
    ")\n",
    "hyper_params = best_h_params\n",
    "clf.set_params(**best_h_params)\n",
    "clf.fit(X_train,y_train)\n",
    "ypred = clf.predict(X_test)\n",
    "report = pd.DataFrame()\n",
    "report['Actual'] = y_test\n",
    "report['Predicted'] = ypred\n",
    "report['Error'] = abs(y_test-ypred)\n",
    "\n",
    "def num(num):\n",
    "    if(num>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "report['Error'] = report['Error'].apply(num)\n",
    "\n",
    "print(report)\n",
    "sreport = pd.DataFrame()\n",
    "sreport['Accuracy of SVM'] = svm_accuracy\n",
    "print(sreport)\n",
    "print(\"Mean: \",np.mean(svm_accuracy))\n",
    "print(\"Std: \",np.std(svm_accuracy))\n",
    "dreport = pd.DataFrame()\n",
    "dreport['Accuracy of DTree'] = dt_accuracy\n",
    "print(\"\\n\")\n",
    "print(dreport)\n",
    "print(\"Mean: \",np.mean(dt_accuracy))\n",
    "print(\"Std: \",np.std(dt_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3743f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
